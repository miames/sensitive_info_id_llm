{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644095ee-3947-4cf1-bd9b-276f82faa70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install & Import Dependencies\n",
    "If you havenâ€™t already installed the BigQuery client library, run this command in a Jupyter notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aad6932-1cce-4a33-9e3e-9928a0d4d45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.10/site-packages (3.25.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.37.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (24.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.12.14)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c6513-9cdc-41a3-a11f-364908e45a18",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create a table with sensitive data in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ae7d87-05fd-4e95-9bb3-6a4b2713b4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pii-iames1.sensitive_data.sensitive_data created or already exists.\n",
      "Data successfully inserted.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Project, Location and Dataset ID\n",
    "PROJECT_ID = \"pii-iames1\"  # Replace with your project ID\n",
    "LOCATION = \"us-central1\"  # Replace with your location, e.g. us-central1\n",
    "DATASET_ID = \"sensitive_data\"  \n",
    "TABLE_ID = \"sensitive_data\"\n",
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Define the schema for the table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"full_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"email\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"phone_number\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"f22_ceiling_height_ft\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"f22_max_speed_mach\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"f22_link16_frequency_mhz\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"HAMMR_radar_range_miles\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"classified_project_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"controlled_technical_doc\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"military_specification\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"restricted_funding_source\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"department\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"project_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"creation_date\", \"DATE\"),\n",
    "]\n",
    "\n",
    "# Construct a full table reference\n",
    "table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "\n",
    "# Create the table\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table = client.create_table(table, exists_ok=True)\n",
    "\n",
    "print(f\"Table {table_ref} created or already exists.\")\n",
    "\n",
    "# Insert sample data into the table\n",
    "rows_to_insert = [\n",
    "    (1, \"Alice Johnson\", \"alice.johnson@example.com\", \"123-456-7890\", 72000, 2.25, 1210, 125, \"Project Phantom\", \"TechSpec_Alpha\", \"MIL-STD-882E\", \"DARPA\", \"R&D\", \"PJT001\", \"2024-01-01\"),\n",
    "    (2, \"Bob Smith\", \"bob.smith@example.com\", \"234-567-8901\", 72000, 2.25, 1210, 125, \"Project Shadow\", \"TechSpec_Beta\", \"MIL-STD-1472\", \"USAF\", \"Operations\", \"PJT002\", \"2024-01-02\"),\n",
    "    (3, \"Charlie Davis\", \"charlie.davis@example.com\", \"345-678-9012\", 72000, 2.25, 1210, 125, \"Project Nightfall\", \"TechSpec_Gamma\", \"MIL-STD-810H\", \"NAVY\", \"Engineering\", \"PJT003\", \"2024-01-03\"),\n",
    "    (4, \"Dana White\", \"dana.white@example.com\", \"456-789-0123\", 72000, 2.25, 1210, 125, \"Project Falcon\", \"TechSpec_Delta\", \"MIL-STD-461G\", \"ARPA\", \"Security\", \"PJT004\", \"2024-01-04\"),\n",
    "    (5, \"Eve Green\", \"eve.green@example.com\", \"567-890-1234\", 72000, 2.25, 1210, 125, \"Project Storm\", \"TechSpec_Epsilon\", \"MIL-STD-464C\", \"DoD\", \"Logistics\", \"PJT005\", \"2024-01-05\"),\n",
    "    (6, \"Frank Brown\", \"frank.brown@example.com\", \"678-901-2345\", 72000, 2.25, 1210, 125, \"Project Thunder\", \"TechSpec_Zeta\", \"MIL-STD-3023\", \"DARPA\", \"R&D\", \"PJT006\", \"2024-01-06\"),\n",
    "    (7, \"Grace Hall\", \"grace.hall@example.com\", \"789-012-3456\", 72000, 2.25, 1210, 125, \"Project Eclipse\", \"TechSpec_Eta\", \"MIL-STD-889D\", \"USAF\", \"Operations\", \"PJT007\", \"2024-01-07\"),\n",
    "    (8, \"Hank Lee\", \"hank.lee@example.com\", \"890-123-4567\", 72000, 2.25, 1210, 125, \"Project Titan\", \"TechSpec_Theta\", \"MIL-STD-461H\", \"NAVY\", \"Engineering\", \"PJT008\", \"2024-01-08\"),\n",
    "    (9, \"Ivy Adams\", \"ivy.adams@example.com\", \"901-234-5678\", 72000, 2.25, 1210, 125, \"Project Vortex\", \"TechSpec_Iota\", \"MIL-STD-882E\", \"ARPA\", \"Security\", \"PJT009\", \"2024-01-09\"),\n",
    "    (10, \"Jack Wilson\", \"jack.wilson@example.com\", \"012-345-6789\", 72000, 2.25, 1210, 125, \"Project Omega\", \"TechSpec_Kappa\", \"MIL-STD-1472\", \"DoD\", \"Logistics\", \"PJT010\", \"2024-01-10\"),\n",
    "]\n",
    "\n",
    "# Insert the rows into the table\n",
    "errors = client.insert_rows(table, rows_to_insert)\n",
    "\n",
    "if errors:\n",
    "    print(\"Errors occurred while inserting data:\", errors)\n",
    "else:\n",
    "    print(\"Data successfully inserted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a6403-7f86-4a26-8d50-7f4565b92f87",
   "metadata": {},
   "source": [
    "# Python Code to Classify Data Using Gemini Flash\n",
    "This script:\n",
    "Reads data from sensitive_data in BigQuery.\n",
    "Sends the data to Gemini Flash 1.5 for classification.\n",
    "Writes the classification results into classified_data table in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a83fdf-9ea3-4ebb-a230-a549e428abb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing table pii-iames1.sensitive_data.classified_data\n",
      "Created table pii-iames1.sensitive_data.classified_data\n",
      "Successfully classified columns and wrote to pii-iames1.sensitive_data.classified_data\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "\n",
    "# Define the table IDs\n",
    "source_table_id = f\"{PROJECT_ID}.{DATASET_ID}.sensitive_data\"\n",
    "destination_table_id = f\"{PROJECT_ID}.{DATASET_ID}.classified_data\"\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Define the schema for the 'classified_data' table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"column_name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"classification\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "def create_table(table_id, schema):\n",
    "    \"\"\"Creates or replaces a table in BigQuery.\"\"\"\n",
    "    table_ref = bigquery.Table(table_id, schema=schema)\n",
    "\n",
    "    try:\n",
    "        # Delete the existing table if it exists\n",
    "        client.delete_table(table_id, not_found_ok=True)\n",
    "        print(f\"Deleted existing table {table_id}\")\n",
    "\n",
    "        # Create a new table\n",
    "        client.create_table(table_ref)\n",
    "        print(f\"Created table {table_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Table creation failed. Exception: {e}\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def fetch_sample_data(table_id, column_name):\n",
    "    \"\"\"Fetches the first two non-null values from a column in BigQuery.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT {column_name}\n",
    "    FROM `{table_id}`\n",
    "    WHERE {column_name} IS NOT NULL\n",
    "    LIMIT 2\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)\n",
    "    results = [row[column_name] for row in query_job.result()]\n",
    "    return results\n",
    "\n",
    "\n",
    "def classify_column(column_name, sample_values):\n",
    "    \"\"\"Classifies a column based on its name and sample values.\"\"\"\n",
    "    model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "    prompt = f\"\"\"\n",
    "    You are a data classification expert. Your task is to classify the following column based on its name and first two data values.\n",
    "    Classify it as either:\n",
    "    - \"Export Controlled Information (ECI)\"\n",
    "    - \"Personally Identifiable Information (PII)\"\n",
    "    - \"NEITHER\".\n",
    "\n",
    "    Column Name: {column_name}\n",
    "    Sample Values: {sample_values}\n",
    "\n",
    "    Strictly return one of the three categories: \"ECI\", \"PII\", or \"NEITHER\".\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        classification = response.text.strip().upper()\n",
    "\n",
    "        # # Ensure valid classification\n",
    "        # if classification not in [\"ECI\", \"PII\", \"NEITHER\"]:\n",
    "        #     print(f\"Invalid classification received: {classification}. Defaulting to NEITHER.\")\n",
    "        #     classification = \"NEITHER\"\n",
    "\n",
    "        return classification\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying column {column_name}: {e}\")\n",
    "        return \"NEITHER\"  # Default in case of error\n",
    "\n",
    "    \n",
    "def main():\n",
    "    \"\"\"Main function to classify columns based on name and sample values.\"\"\"\n",
    "    \n",
    "    # Create or replace the destination table\n",
    "    if not create_table(destination_table_id, schema):\n",
    "        print(\"Exiting program since we cannot create table.\")\n",
    "        return\n",
    "\n",
    "    # Get schema of source table\n",
    "    table = client.get_table(source_table_id)\n",
    "    source_schema = table.schema\n",
    "\n",
    "    # Prepare rows to insert into the destination table\n",
    "    rows_to_insert = []\n",
    "    for field in source_schema:\n",
    "        column_name = field.name\n",
    "        sample_values = fetch_sample_data(source_table_id, column_name)\n",
    "        classification = classify_column(column_name, sample_values)\n",
    "        \n",
    "        rows_to_insert.append({\n",
    "            \"column_name\": column_name,\n",
    "            \"classification\": classification\n",
    "        })\n",
    "\n",
    "    # Insert rows into BigQuery table\n",
    "    table_ref = client.get_table(destination_table_id)\n",
    "    errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "\n",
    "\n",
    "    if errors:\n",
    "        print(f\"Encountered errors while inserting rows: {errors}\")\n",
    "    else:\n",
    "        print(f\"Successfully classified columns and wrote to {destination_table_id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cb8db-ee68-4305-9ffd-38301c19bf81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# View Classified Table in BigQuery\n",
    "Go to BigQuery and view the classified_data table to view the classes"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
